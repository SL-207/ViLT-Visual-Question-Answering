{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOras3I0QfHgMo08pHxL5vi"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "### 1. Load and Split data",
      "metadata": {
        "id": "MGtLJAC0lA40"
      }
    },
    {
      "cell_type": "code",
      "source": "!pip install -Uqq datasets fsspec transformers evaluate",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEqSpOHkg9At",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748698114669,
          "user_tz": -60,
          "elapsed": 30639,
          "user": {
            "displayName": "Samuel",
            "userId": "07139106576109725916"
          }
        },
        "outputId": "9d9fe32b-fb6a-4b80-e5f6-829fbb13fa71",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-09T16:06:44.443753Z",
          "iopub.execute_input": "2025-06-09T16:06:44.444511Z",
          "iopub.status.idle": "2025-06-09T16:06:48.108097Z",
          "shell.execute_reply.started": "2025-06-09T16:06:44.444467Z",
          "shell.execute_reply": "2025-06-09T16:06:48.107117Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": "from datasets import load_dataset\n\ndata = load_dataset(\"gretelai/gretel-patient-events-v1\")",
      "metadata": {
        "id": "MEQ5-i4ndojC",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748698299175,
          "user_tz": -60,
          "elapsed": 2926,
          "user": {
            "displayName": "Samuel",
            "userId": "07139106576109725916"
          }
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-09T16:01:45.470378Z",
          "iopub.execute_input": "2025-06-09T16:01:45.470596Z",
          "iopub.status.idle": "2025-06-09T16:01:48.468101Z",
          "shell.execute_reply.started": "2025-06-09T16:01:45.470576Z",
          "shell.execute_reply": "2025-06-09T16:01:48.467574Z"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/6.70k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c65715ba00745688b238ba1e4c0c138"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00000-of-00001.parquet:   0%|          | 0.00/1.13M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e2a126e2a2a49908d97cb7d6497be2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/7348 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "210b84791e4e41e9b21ad790a8203741"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "data = data[\"train\"].train_test_split(test_size=0.2, seed=42)\ndata",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qs9WAdNt4jw",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748698302893,
          "user_tz": -60,
          "elapsed": 12,
          "user": {
            "displayName": "Samuel",
            "userId": "07139106576109725916"
          }
        },
        "outputId": "3335470b-84e2-4c16-9c85-adc10fb96ff3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-09T16:01:48.469489Z",
          "iopub.execute_input": "2025-06-09T16:01:48.470011Z",
          "iopub.status.idle": "2025-06-09T16:01:48.486288Z",
          "shell.execute_reply.started": "2025-06-09T16:01:48.469991Z",
          "shell.execute_reply": "2025-06-09T16:01:48.485415Z"
        }
      },
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['patient_id', 'first_name', 'last_name', 'date_of_birth', 'sex', 'race', 'weight', 'height', 'event_id', 'event_type', 'event_date', 'event_name', 'provider_name', 'reason', 'result', 'details', 'notes'],\n        num_rows: 5878\n    })\n    test: Dataset({\n        features: ['patient_id', 'first_name', 'last_name', 'date_of_birth', 'sex', 'race', 'weight', 'height', 'event_id', 'event_type', 'event_date', 'event_name', 'provider_name', 'reason', 'result', 'details', 'notes'],\n        num_rows: 1470\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "### 2. Preprocess",
      "metadata": {
        "id": "CIK43J5HqRmK"
      }
    },
    {
      "cell_type": "code",
      "source": "from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "6febfaa2005c4789bf3673afaebd20dc",
            "86fc8444a2d84919b877c311ba9ee6a4",
            "e06439e572da4826a5e522d14d615347",
            "bbc080528e4d47ef83720b6820da4e9f",
            "fc8ce1260875449b81b2a9c7db4ccd5a",
            "a0eb2a89907441d9ae5573027f22dfb2",
            "8e5d16fd3ac345dcb336a5d0ea3a3231",
            "937618d3ed284a87b16e0fb560c45408",
            "7acb94435a6c4b5892b7d3328a755283",
            "f6ba9403acba4f5e86a81313c6205e37",
            "fdab9e1bc04c403f86c1902e99975643",
            "3fb3cca5682f42daa0ae4ffebceefd77",
            "53bf09da71d8467088bc4a51408d8ae9",
            "6509c2f0593e4cf4b83e3ef92da1ec3e",
            "720835f2c10c4007868a7dd93cb5d1c0",
            "cb1c76a00ad1482589348d1305c32cb8",
            "2421d6213f1246089813d674bb4041f8",
            "aeede78f03b44da9a9b40c526467942f",
            "2ab7d4dd1f8f4684807a22480ecd6a7a",
            "0c7d8496e00c47ac844d3e455b561fac",
            "cfaba0e25aff48518a52dabd883cd4c8",
            "cdfb8f40e4a3411095348c61c66aa90d",
            "48a530a0ec1e4d9489bdc14ad51caff7",
            "5fd405ebe6a44b75bf28541a62b3d57d",
            "64048c5be53a4eb99dfab70c606c6ea4",
            "a816faf3a66c4a8dacb3ae7a2e1bc6d1",
            "f7b73a5bac404fbe94927718da127735",
            "161ff4a1bb0743b894556d03dfce4010",
            "58059913d6f64fcea080b53b2a734839",
            "bc136cc5708e4d0db230ec3dbdde48f5",
            "e7187d2a6bb84a33b6db444caf9594d2",
            "cc4633ee1ffb40ff846f88e2fbf2514a",
            "dfff5ec76bcf40f9831a3fcce74be4dc",
            "e256c24841bd491d9bbcc18fc9b57097",
            "c0298e57d5b74467b19c4369a9b77dc6",
            "3fecf9655aef41059820f380687b3246",
            "0111b2ad537a4e20a4be1a0ff9e0629c",
            "d0233ec1c865404d9d79ef468d627fea",
            "8cb8faefd1094ef2a4af919d1ce07cb5",
            "61ff405c52464b94a0d1117f7ff61c26",
            "3d82599b1ca742258505d705df412869",
            "c65fa7f605644b619ae724a2507879e2",
            "4bd7c2f9c59e44a7bdc4a340aa80fe32",
            "ae0a6f9815f54159bd69a80babf07168"
          ]
        },
        "id": "1bNKvlSTqVm3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748698131754,
          "user_tz": -60,
          "elapsed": 9323,
          "user": {
            "displayName": "Samuel",
            "userId": "07139106576109725916"
          }
        },
        "outputId": "de6e5f1f-9bc9-4290-9486-5949fd6bfdbb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-09T16:01:48.487110Z",
          "iopub.execute_input": "2025-06-09T16:01:48.487390Z",
          "iopub.status.idle": "2025-06-09T16:01:48.688206Z",
          "shell.execute_reply.started": "2025-06-09T16:01:48.487366Z",
          "shell.execute_reply": "2025-06-09T16:01:48.687633Z"
        }
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": "def preprocess(samples):\n    texts = []\n    for i in range(len(samples[\"patient_id\"])):\n        fields = [\n            f\"Patient ID: {samples['patient_id'][i]}\",\n            f\"Name: {samples['first_name'][i]} {samples['last_name'][i]}\",\n            f\"DOB: {samples['date_of_birth'][i]}\",\n            f\"Sex: {samples['sex'][i]}\",\n            f\"Race: {samples['race'][i]}\",\n            f\"Weight: {samples['weight'][i]} kg\",\n            f\"Height: {samples['height'][i]} cm\",\n            f\"Event ID: {samples['event_id'][i]}\",\n            f\"Event Type: {samples['event_type'][i]}\",\n            f\"Event Date: {samples['event_date'][i]}\",\n            f\"Event Name: {samples['event_name'][i]}\",\n            f\"Provider: {samples['provider_name'][i]}\",\n            f\"Reason: {samples['reason'][i]}\",\n            f\"Result: {samples['result'][i]}\",\n            f\"Details: {samples['details'][i]}\",\n            f\"Notes: {samples['notes'][i]}\"\n        ]\n        # Only include non-empty fields\n        text = \", \".join([f for f in fields if f and f != 'nan'])\n        texts.append(text)\n    model_inputs = tokenizer(texts)\n    # model_inputs[\"text\"] = texts\n    return model_inputs\n\n\ntokenized_data = data.map(preprocess, batched=True, remove_columns=data[\"train\"].column_names)",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "38687545ad864f9996b65f230baf4377",
            "0f92c15fa3a94902af65b294052df46e",
            "769d4804c25f4490ac0d5aadb6d9abab",
            "f55d809f4d4d438ab7928d3c0a802654",
            "d3b108e651734a09a43d4b6cbcb8acc2",
            "c525335d333848d4a02aeaeaf533803d",
            "be0ff24c17064cf68a5334433f72c479",
            "da60a883fdb34cf6bba15f051089b453",
            "92d972f139f04479bb43cd54163b138b",
            "b18ada60f62c419bbd81b81a3c07f80d",
            "6a4cbf0cd04c4045b1240212f73b349b",
            "a407c1cda5ca4f5682b5615ecaa9f7cd",
            "402ba6c4c73040eda122c2da01235511",
            "55758be1801041f2a288a18e9c380b28",
            "e1895e2512d941c0bc650fb00ef95f2f",
            "30eb33ad15154a36865171f8c6f6fd33",
            "b8946e8c0604431f87212b2c83cb2fb4",
            "0b58205aff054cc591d4c77d9d5bdd3c",
            "328e0df245f746ad8c01fb9ecccdb280",
            "a190652789b24929a6aeb54b31b238c9",
            "00501fb6e9d948cfb0f8b3418d82b0a1",
            "1fc0336518924f8b9fbf72662e4c55ed"
          ]
        },
        "id": "07Eb2ODEek8g",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748698331035,
          "user_tz": -60,
          "elapsed": 7943,
          "user": {
            "displayName": "Samuel",
            "userId": "07139106576109725916"
          }
        },
        "outputId": "31f7a8f9-4809-4287-9e8b-73169fb38635",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-09T16:01:48.688924Z",
          "iopub.execute_input": "2025-06-09T16:01:48.689122Z",
          "iopub.status.idle": "2025-06-09T16:01:50.788376Z",
          "shell.execute_reply.started": "2025-06-09T16:01:48.689108Z",
          "shell.execute_reply": "2025-06-09T16:01:50.787777Z"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/5878 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85e701ac5f924472ae539ef27d447dbe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1470 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "135211ce68b44ace8115318718c65116"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "tokenized_data",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkC2fmKKhKmC",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748698333662,
          "user_tz": -60,
          "elapsed": 7,
          "user": {
            "displayName": "Samuel",
            "userId": "07139106576109725916"
          }
        },
        "outputId": "94d78d54-98e2-47ab-c6cf-cf6356249b92",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-09T16:07:10.297536Z",
          "iopub.execute_input": "2025-06-09T16:07:10.297875Z",
          "iopub.status.idle": "2025-06-09T16:07:10.304484Z",
          "shell.execute_reply.started": "2025-06-09T16:07:10.297846Z",
          "shell.execute_reply": "2025-06-09T16:07:10.303527Z"
        }
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 5878\n    })\n    test: Dataset({\n        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1470\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "print(tokenized_data[\"train\"][0])",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DsgZmbFrhGp",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748698360612,
          "user_tz": -60,
          "elapsed": 5,
          "user": {
            "displayName": "Samuel",
            "userId": "07139106576109725916"
          }
        },
        "outputId": "65a36c76-5108-47a2-fb6f-cf0272fde998",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-09T16:07:15.689604Z",
          "iopub.execute_input": "2025-06-09T16:07:15.690297Z",
          "iopub.status.idle": "2025-06-09T16:07:15.696426Z",
          "shell.execute_reply.started": "2025-06-09T16:07:15.690266Z",
          "shell.execute_reply": "2025-06-09T16:07:15.695433Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{'input_ids': [1, 18276, 4843, 4576, 35, 4751, 438, 12, 401, 27873, 28621, 12, 134, 6, 10704, 35, 6939, 15738, 3578, 6, 14010, 387, 35, 12087, 73, 996, 73, 1646, 4432, 6, 15516, 35, 23172, 6, 8989, 35, 735, 6, 17515, 35, 10572, 4, 288, 14091, 6, 37099, 35, 5138, 4, 288, 25434, 6, 11373, 4576, 35, 132, 6, 11373, 7773, 35, 3067, 37361, 6, 11373, 10566, 35, 15140, 73, 1092, 73, 844, 1922, 6, 11373, 10704, 35, 12464, 23063, 6, 31314, 35, 7312, 17129, 824, 6, 31613, 35, 31424, 6, 33868, 35, 23867, 16003, 46224, 6, 10574, 35, 25522, 48268, 17152, 35, 12464, 14194, 1487, 2849, 8293, 9799, 46224, 5542, 678, 7482, 34049, 38951, 4, 17638, 1720, 18719, 9, 1416, 8, 55, 2167, 3044, 13, 33945, 25934, 16836, 13310, 12673, 4, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": "from transformers import DataCollatorForLanguageModeling\n\n# collate_fn with masking and dynamic padding\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=True,\n    mlm_probability=0.15,\n)",
      "metadata": {
        "id": "EDPRL7RPmf1G",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748698371513,
          "user_tz": -60,
          "elapsed": 2,
          "user": {
            "displayName": "Samuel",
            "userId": "07139106576109725916"
          }
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-09T16:07:18.409640Z",
          "iopub.execute_input": "2025-06-09T16:07:18.410518Z",
          "iopub.status.idle": "2025-06-09T16:07:18.415033Z",
          "shell.execute_reply.started": "2025-06-09T16:07:18.410480Z",
          "shell.execute_reply": "2025-06-09T16:07:18.414340Z"
        }
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": "### 3. Prepare and Train model",
      "metadata": {
        "id": "tvGBD0OVyV-0"
      }
    },
    {
      "cell_type": "code",
      "source": "import torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3eOe2Ff9sTSA",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748698142988,
          "user_tz": -60,
          "elapsed": 57,
          "user": {
            "displayName": "Samuel",
            "userId": "07139106576109725916"
          }
        },
        "outputId": "eb1dbeee-d57d-4df7-bbca-c518f84ded02",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-09T16:02:27.422673Z",
          "iopub.execute_input": "2025-06-09T16:02:27.423167Z",
          "iopub.status.idle": "2025-06-09T16:02:27.428560Z",
          "shell.execute_reply.started": "2025-06-09T16:02:27.423140Z",
          "shell.execute_reply": "2025-06-09T16:02:27.427601Z"
        }
      },
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'cuda'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": "from transformers import AutoModelForMaskedLM, TrainingArguments, Trainer\n\nmodel = AutoModelForMaskedLM.from_pretrained(\"microsoft/deberta-base\")\nmodel",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dKKVukIyjKC",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748698583617,
          "user_tz": -60,
          "elapsed": 1049,
          "user": {
            "displayName": "Samuel",
            "userId": "07139106576109725916"
          }
        },
        "outputId": "c26e433b-70f4-4059-eb0a-a13af73622f8",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-09T16:08:45.486486Z",
          "iopub.execute_input": "2025-06-09T16:08:45.487167Z",
          "iopub.status.idle": "2025-06-09T16:08:45.491078Z",
          "shell.execute_reply.started": "2025-06-09T16:08:45.487134Z",
          "shell.execute_reply": "2025-06-09T16:08:45.490233Z"
        }
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": "from peft import LoraConfig, TaskType, get_peft_model\n\n# specify how to build peft model\npeft_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"in_proj\"],  # inject for every in_proj layer\n    lora_dropout=0.05\n)\n\n# freeze everything but adapters\nmodel = get_peft_model(model, peft_config)\n\n# unfreeze untrained cls head for mlm\nfor name, param in model.named_parameters():\n    if \"cls.predictions.\" in name:\n        param.requires_grad = True\n\n# Define a new “patched” forward that removes 'num_items_in_batch'\n# _original_forward = model.forward\n\n# def _forward_without_num_items(*args, **kwargs):\n#     kwargs.pop(\"num_items_in_batch\", None)\n#     return _original_forward(*args, **kwargs)\n\n# model.forward = _forward_without_num_items\n\nmodel.print_trainable_parameters()",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbiDjQJfzdez",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748700231384,
          "user_tz": -60,
          "elapsed": 35,
          "user": {
            "displayName": "Samuel",
            "userId": "07139106576109725916"
          }
        },
        "outputId": "75a0f04c-6c25-4196-ebd4-4c3cc88c1878",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-08T19:51:37.438628Z",
          "iopub.execute_input": "2025-06-08T19:51:37.439461Z",
          "iopub.status.idle": "2025-06-08T19:51:37.464698Z",
          "shell.execute_reply.started": "2025-06-08T19:51:37.439408Z",
          "shell.execute_reply": "2025-06-08T19:51:37.464149Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "trainable params: 937,305 || all params: 139,539,033 || trainable%: 0.6717\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": "import evaluate\nfrom transformers import EvalPrediction\n\n# Load metric from evaluate\nmetric = evaluate.load(\"perplexity\")\n\n# Custom compute_metrics function\ndef compute_metrics(eval_pred: EvalPrediction):\n    logits, labels = eval_pred\n    preds = logits.argmax(axis=1)\n    results = metric.compute(predictions=preds, references=labels)\n    return results",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "e6bf4844ed044e88ac112b2dc4eee068",
            "40450050c45940bab4e3d7a9fe07351c",
            "8f433a08f43c40e091852e702bd743b9",
            "ebda19b5b5e74cf7b0e96a1d9ca9cc29",
            "e81f67d26e124ea6b437a563191216cb",
            "e8d5bafc764b47ddae6dd1b5ec8f18c4",
            "a374dcdf4d1d44c188eb7cf05460e28a",
            "a6f1a9278c5445a3ad64c02de669f03e",
            "507e10c7373a4c40a128ed65b1928ab6",
            "492f7ba0b3f544bdb64fa735e445a749",
            "415dad08049140d7b67e34621402bc39",
            "80c3afe65c44498aba972d8200b25cbf",
            "9dfe1367705140ed95a5c73055162a30",
            "eb923813bce643f295da5c0ab20ccd6a",
            "86530b62090e43e5a1f3d31d3b487975",
            "59aa60c56b364afa8962c2c52319b5f6",
            "bd1e635b175d47c48d515f68f3f074c1",
            "a5dd2fec37754dd2b751593d204a6078",
            "ce709c11343647c0877b5b2bc20e6a7f",
            "370a48c1224541729a3bf6ef43eb3353",
            "c2dcd8e012774a2bbd70c3a412f20b45",
            "9449c3151a484edba531671e0f45c79a"
          ]
        },
        "id": "MihIpdgjeIog",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1748698178504,
          "user_tz": -60,
          "elapsed": 1903,
          "user": {
            "displayName": "Samuel",
            "userId": "07139106576109725916"
          }
        },
        "outputId": "daa8e01d-6c4e-4ba4-b23b-62e5010f460f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-07T20:04:42.547250Z",
          "iopub.execute_input": "2025-06-07T20:04:42.548079Z",
          "iopub.status.idle": "2025-06-07T20:04:42.959308Z",
          "shell.execute_reply.started": "2025-06-07T20:04:42.548047Z",
          "shell.execute_reply": "2025-06-07T20:04:42.958473Z"
        }
      },
      "outputs": [],
      "execution_count": 27
    },
    {
      "cell_type": "code",
      "source": "train_args = TrainingArguments(\"results2\",\n                               eval_strategy=\"no\",\n                               max_steps= 2000,\n                               # eval_steps= 500,\n                               logging_steps=200,\n                               per_device_train_batch_size=4,\n                               per_device_eval_batch_size=4,\n                               weight_decay=0.01,\n                               remove_unused_columns=False,\n                               report_to=\"none\")\n\ntrainer = Trainer(model=model,\n                  args=train_args,\n                  train_dataset=tokenized_data[\"train\"],\n                  # eval_dataset=tokenized_data[\"test\"],\n                  data_collator=data_collator,\n                  # compute_metrics=compute_metrics\n                 )\ntrainer.train()",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-08T19:51:42.246312Z",
          "iopub.execute_input": "2025-06-08T19:51:42.247076Z",
          "iopub.status.idle": "2025-06-08T19:57:39.359219Z",
          "shell.execute_reply.started": "2025-06-08T19:51:42.247052Z",
          "shell.execute_reply": "2025-06-08T19:57:39.358344Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2000/2000 05:56, Epoch 2/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>200</td>\n      <td>5.093700</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>2.842000</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>2.497600</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>2.309900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.192400</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>2.134500</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>2.061600</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>1.960900</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>1.952200</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.016500</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=2000, training_loss=2.506134017944336, metrics={'train_runtime': 356.6675, 'train_samples_per_second': 44.86, 'train_steps_per_second': 5.607, 'total_flos': 1521689573089764.0, 'train_loss': 2.506134017944336, 'epoch': 2.7210884353741496})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": "### 4. Test inference",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "tokenizer.decode(tokenized_data['test'][0]['input_ids'])",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-09T16:18:10.075348Z",
          "iopub.execute_input": "2025-06-09T16:18:10.075666Z",
          "iopub.status.idle": "2025-06-09T16:18:10.081636Z",
          "shell.execute_reply.started": "2025-06-09T16:18:10.075643Z",
          "shell.execute_reply": "2025-06-09T16:18:10.081109Z"
        }
      },
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'[CLS]Patient ID: pmc-6186366-2, Name: Yasir Shah, DOB: 03/18/1961, Sex: Male, Race: Asian, Weight: 176.0 kg, Height: 68.0 cm, Event ID: 4, Event Type: Surgery, Event Date: 06/28/2022, Event Name: Biopsy Procedure, Provider: Specialist Dr. Liu, Reason: To confirm biopsy recommendation, Result: Esophageal tissue samples obtained, Details: {\"intensity\":null,\"location\":\"esophagus\"}, Notes: Biopsy conducted, awaiting histopathological results to determine presence of Barrett\\'s or other changes.[SEP]'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "source": "text = 'Patient ID: pmc-6186366-2, Name: Yasir Shah, DOB: 03/18/1961, Sex: Male, Race: Asian, Weight: 176.0 kg, Height: 68.0 cm, Event ID: 4, Event Type: Surgery, Event Date: 06/28/2022, Event Name: [MASK] Procedure, Provider: Specialist Dr. Liu, Reason: To confirm biopsy recommendation, Result: Esophageal tissue samples obtained, Details: {\"intensity\":null,\"location\":\"esophagus\"}, Notes: Biopsy conducted, awaiting histopathological results to determine presence of Barrett\\'s or other changes.'\ninputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n\nwith torch.inference_mode():\n    y_logits = model(**inputs).logits\n    print(y_logits.shape)\n\nsequence = []\nfor token in y_logits.squeeze(0):\n    sequence.append(tokenizer.decode(token.argmax(0)))\nprint(sequence)",
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-09T16:16:51.415100Z",
          "iopub.execute_input": "2025-06-09T16:16:51.415869Z",
          "iopub.status.idle": "2025-06-09T16:16:51.419307Z",
          "shell.execute_reply.started": "2025-06-09T16:16:51.415847Z",
          "shell.execute_reply": "2025-06-09T16:16:51.418479Z"
        }
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}
